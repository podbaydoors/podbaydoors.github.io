<!DOCTYPE html>
<html>
<head>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Gruppo&display=swap" rel="stylesheet">
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hi-Bit Pixel Art Renderer - Part 1</title>
  <link rel="stylesheet" href="../../style.css">
</head>
<body>
  <h1><a class="site-title" href="../../index.html">pod bay doors</a></h1>
  <hr style="border: none; border-top: 1px solid lightgrey;">
<h1>Writting a Hi-Bit pixel art renderer - Part 1</h1>
<p>In this series of articles I'm going to cover the development of my hi-bit pixel art renderer. By hi-bit I mean a 2d rendering system that has a retro, pixel art aesthetic but doesn't constrain itself to the limitations of retro hardware. This is in contrast to games such as Shovel Knight that aim to faithfully adhere to the limitations of a specific platform. Hi-bit games will often use a wider color pallette or use shader techniques that wouldn't have been possible on retro hardware.</p>
<p>The renderer was built using c++ and opengl. But I the techniques I discuss here should be usable using any api or 3rd party engine.</p>
<figure>
    <img title="" src="Assets/omega.png" alt="" data-align="center">
    <figcaption><small>Omega by pieceoftoast</small></figcaption>
</figure>

<p>This image was created by Deviant Art user pieceoftoast (link). This is artwork, not a screen shot from a game. I really liked how this concept image evoked older games like those made by Sierra On-Line or Lucas Arts but also had a lot of interesting modern flourishes such as glowing textures, normal mapping and smooth lighting. I thought it would be fun to make a renderer that could replicate all these features in-engine. For example, the glow around the lights should not be baked into the art assets but instead be drawn by the rendering system.</p>
<p>During game development preproduction, concept artists often create images that illustrate how all the rendering features should look in the final game. This process is usually a back-and-forth collaboration between rendering team the art team. Artists will start with a high level image or description of how they want the game to look. Programmers will then suggest some rendering techniques that might achieve this look. Back and forth this goes until a concept is agreed upon. Of course, like everthing in game development, this plan is likely to change a fair bit during production. But at least you have a well though through starting plan. We often called these images "game in a frame". To me this image seemed like the perfect "game in a frame" to start development. </p>
<p>My first step was to identify all the rendering features from the concept image that'd I'd need to support in-engine. Here's what I came up with:</p>
<ul>
<li>Consistent texel size. Texels are always the same size on screen. </li>
<li>Arbitrary number of layers. I counted at least 8 layers in the scene. Some layers should have parallax with respect to each other. For other sets of layers we will not want them to parallax.</li>
<li>Normal mapped dynamic lighting. Look at the tile edges near the lit signs and notice how the tile edges are lit up.</li>
<li>Dynamic cast shadows</li>
<li>Glowing textures</li>
<li>Lens flares</li>
</ul>
<p>I also added a goal that wasn't necessarily informed by the concept image.</p>
<ul>
<li>Pixel perfect texture sampling. Screen pixels that overlap multiple texels (from the same tile or adjacent tiles) should perfectly blend the percentage contribution from each texel.</li>
</ul>
<h2>Layout of the scene</h2>
<h3>Approach 1 - Orthographic 2D layers</h3>
<p>The first thing I needed to figure out was how to layout objects in the scene. The objects of the scene being textured quads. My first approach was to copy how 2D games would have done it before the advent of 3D rendering: Represent the scene as a series of 2D layers and assign each layer a parallax scalar. Objects can then be placed in layers. At render time, I drew each layer back-to-front using an orthographic view-projection matrix. When calculating the view matrix for a layer, I'd scale the translation by the parallax amount. So for a layer with parallax scalar equal to 1, the layer would track the camera exactly. For a layer with parallax scalar set to .5, the objects in that layer would move at half the speed. </p>
<figure>
    <img title="" src="Assets/LayerDiagram.jpg" alt="" data-align="center" width="500">
    <figcaption><small>2D background and foreground layers combined for final image</small></figcaption>
</figure>

<p>This approach quickly proved limiting and cumbersome. Scene management, such as selecting and moving objects, was complicated by the presence of scene layers. Moving an object farther back in the scene required moving the object to another layer. If that layer didn't have the parallax amount I wanted, I'd have to create another layer. I realized that if I wanted more than a few layers in the scene then I'd want to find a different approach.</p>
<h3>Approach 2 - 3D perspective with scale</h3>
<p>For my next approach, I extended the renderer to 3D. I removed the concept of layers and gave each object a z position. The scene was rendered using a perspective projection matrix which gave the desired parallax effect when the camera moved in the xy plane. But by using a perpective projection objects farther in the background were drawn smaller on screen. This broke the goal of having a consistent texel size. To fix this, I calculated a xy scale for each object depending on its distance from the camera. </p>
<figure>
    <img title="" src="Assets/ScaledPerspectiveDiagram.jpg" alt="" data-align="center" width="500">
    <figcaption><small>Textures scaled to maintain consistent texel size</small></figcaption>
</figure>

<p>With this approach the camera can move in x and y but must be fixed in z. Moving in z will cause closer objects to scale up/down faster than objects farther away. This will break the consitent texel size goal.</p>
<p>Here is how I calculated the camera distance. I picked z==0 as the location at which object scale would equal 1.</p>
<pre><code>//Code that runs at renderer startup
//Set camera distance so that the height of xy plane at z==0 is gScreenHeightInTexels.
gCameraDist = (gScreenHeightInTexels)/(2.f*tanf(DegToRad(.5f*gRenderVerticalFOVDegrees)));

//Returns how much to scale a textured quad so that texels are a consistent on-screen size
float GetTexelScaleAtZ( float z )
{
    float scale = (gCameraDist-z)/gCameraDist;
    return scale;
}
</code></pre>
<p>When placing or moving an object, I'd set the scale by calling the function GetTexelScaleAtZ. This technique worked well and I was mostly satisfied with it. There was a bit of code complexity in managing object scale (I recall moving multiple objects at different z-depths was a tricky problem to get right). But I proceeded with development using this approach for quite a while. It wasn't until I began implementing shadows that I started to rethink it. Basically, if we project a shadow onto an object farther in the distance, the shadow texels will be smaller than the texels of the surface they are projected onto. We can use nearest sampling to make them the correct size but then we are downsampling our pixel art. And downsampled pixel art never looks good.</p>
<h3>Approach 3 - Skewed orthographic</h3>
<p>To make the shadows look good I knew I needed to go back to using an orthographic projection with no object scaling. But with a standard orthographic projection there is no parralax. I then realized I could get parallax by applying a skew transformation to the view matrix. The skew transformation would translate objecs in the x&amp;y direction proportional to their z position. Here's how I did it.</p>
<p>-Pick a world position </p>
<video autoplay loop muted playsinline>
  <source src="Assets/Omega.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
</body>
</html>
